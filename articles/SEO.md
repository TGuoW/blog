## 搜索引擎工作原理
要了解SEO，首先得了解搜索引擎的工作原理，其原理是比较复杂，流程简化如下：

### 爬虫抓取网页内容
一般爬虫抓取页面内容是先从一个页面出发，从中提取出其他页面的链接，然后当作下一个请求的对象，一直重复这个过程。所以要有良好的SEO，需要你在各大网站上拥有外链，这样会提高你的网站被搜索引擎爬虫的几率。

### 分析网页内容
爬虫拿到HTML之后，就会对其内容进行分析。一般需要进行去杂、分词、简历索引数据库。什么是索引数据库呢？简单地说就是记录一个词在哪些文档中出现、出现次数、出现的位置等等。为什么要简历索引数据库呢？是为了快速查找。

### 搜索和排序
搜索会根据你输入的关键词，分别查询其对应的索引数据库，并对结果进行处理和排序。

## 前端编码的SEO
### 网站结构
网站结构要清晰。一般网站的结构是树形的，一般分为三个层次：首页 → 频道页（列表页） → 文章页（详情页）。
网站的结构要扁平。结构层数越少越好，一般不要超过三层，搜索引擎一般到了第三层就不想继续深入地爬取了。多数的网站，例如掘金、雪球等，他们的网站结构是两层，他们的首页和频道页是同一个页面。

### 导航
页面应该要有简明的导航。导航可以让搜索引擎知道网站的结构，也可以让搜索引擎知道当前页面在网站结构所在的层次。

建议：

* 每一个页面都包含导航。
* 对于内容较多的网站可以采用面包屑导航。
* 链接使用文字链接，如果是图片，则通过alt属性告知搜索引擎链接的指向。

## 规范的URL
规范、简单、易理解的URL能让搜索引擎更好地抓取内容。

建议：

* 同一个页面，只对应一个url 。多个url可以采用301进行重定向。
* url可以反应网页内容以及网站结构信息。例如www.a.com/blog、www.a.com/blog/123、www.a.com/article。
* url尽量简短。
* 尽量减少动态url中包含的变量参数。

### 提交Sitemap
Sitemap 可通知搜索引擎他们网站上有哪些可供抓取的网页，以便搜索引擎可以更加智能地抓取网站。

### robot.txt
搜索引擎爬行网站第一个访问的文件就是robots.txt。在这个文件中声明该网站中不想被蜘蛛访问的部分，这样，该网站的部分或全部内容就可以不被搜索引擎访问和收录了，或者可以通过robots.txt指定使搜索引擎只收录指定的内容。

### 合理的HTTP返回码
不同的返回码，搜索引擎的处理逻辑是不一样的。

* 如果站点临时关闭，当网页不能打开时，建议使用503状态。503可以告知百度spider该页面临时不可访问，请过段时间再重试。
* 如果百度spider对您的站点抓取压力过大，请尽量不要使用404，同样建议返回503。这样百度spider会过段时间再来尝试抓取这个链接，如果那个时间站点空闲，那它就会被成功抓取了。
* 有一些网站希望百度只收录部分内容，例如审核后的内容，累积一段时间的新用户页等等。在这种情况，建议新发内容暂时返回403，等审核或做好处理之后，再返回正常状态的返回码。
* 站点迁移，或域名更换时，请使用301返回。

### 合适的title
title是告诉搜索引擎网页的主要内容。

* 每个网页应该有一个独一无二的标题，切忌所有的页面都使用默认标题
* 标题要主题明确和精练，包含这个网页中最重要的内容，且不罗列与网页内容不相关的信息
* 用户浏览通常是从左到右的，重要的内容应该放到title的靠前的位置

百度建议描述：

* 首页：网站名称 或者 网站名称_服务介绍/产品介绍
* 频道页：频道名称_网站名称
* 文章页：文章标题_频道名称_网站名称

### 合适的description
description是对网页内容的精练概括。这个标签存在与否不影响网页权值，只会用做搜索结果摘要的一个选择目标。

百度推荐做法：

* 为每个网页创建不同的description，避免所有网页都使用同样的描述
* 网站首页、频道页、产品参数页等没有摘要的网页最适合使用description
* 准确的描述网页，不要堆砌关键词，长度合理
